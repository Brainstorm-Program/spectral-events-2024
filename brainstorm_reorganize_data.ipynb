{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b2964e",
   "metadata": {
    "id": "b9b2964e"
   },
   "source": [
    "# SEEG Brainstorm Challenge 2024\n",
    "\n",
    "Thank you for joining us for the Brainstorm Challenge 2024! This script is designed to re-organize the data and save each participants data into a CSV file. We developed this script to give our attendees direct access to the data, rather than needing to navigate the necessary complex file structure of the raw data. As such, the result of this script - the CSV files - can be used directly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6615c",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "### Import Modules\n",
    "First, we will need to import different modules for this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed889d03",
   "metadata": {
    "id": "ed889d03"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import itertools\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import bz2\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8f22a",
   "metadata": {},
   "source": [
    "### Define Functions\n",
    "\n",
    "We will load some basic functions that Bryan Zheng wrote to read and organize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat(fmat):\n",
    "    return sio.loadmat(fmat, struct_as_record=False, squeeze_me=True)\n",
    "\n",
    "def mat_to_dict(mat):\n",
    "    \"\"\" convert mat_struct object to a dictionary recursively\n",
    "    \"\"\"\n",
    "    dict = {}\n",
    "\n",
    "    for field in mat._fieldnames:\n",
    "        val = mat.__dict__[field]\n",
    "        if isinstance(val, sio.matlab.mat_struct):\n",
    "            dict[field] = mat_to_dict(val)\n",
    "        else:\n",
    "            dict[field] = val\n",
    "\n",
    "    return dict\n",
    "\n",
    "def read_bhv(behavior):\n",
    "    \"\"\" load behavioral data from .mat file and extra trial data\n",
    "        returns dictionary of all behavioral data per trial\n",
    "    \"\"\"\n",
    "    bhv = {}\n",
    "    existing_trials = 0\n",
    "\n",
    "    f = load_mat(behavior)\n",
    "    for k in f.keys():\n",
    "        if k[0:5] == 'Trial' and k[5:].isdigit():\n",
    "            trial = f[k]\n",
    "            trial_num = int(k[5:]) + existing_trials\n",
    "            bhv[trial_num] = mat_to_dict(trial)\n",
    "\n",
    "    return bhv\n",
    "\n",
    "def load_pkl(path):\n",
    "    \"\"\" loads compressed pickle file called by load_electrodes() \"\"\"\n",
    "\n",
    "    with bz2.open(path, 'rb') as f:\n",
    "        neural_data = cPickle.load(f)\n",
    "    return neural_data\n",
    "\n",
    "def find_trials(events, verbose=False):\n",
    "    \"\"\" finds *all* trials with associated codes in an events file \"\"\"\n",
    "    events_signal = load_pkl(events)\n",
    "    codes = events_signal['signal']\n",
    "    fs = events_signal['fs']\n",
    "\n",
    "    trials = {0: []}\n",
    "\n",
    "    count = 0\n",
    "    for c in codes:\n",
    "        if c[0] == 9:\n",
    "            count += 1\n",
    "            trials[count] = [c]\n",
    "            if count > 1 and trials[count-1][-1][0] != 18 and verbose:\n",
    "                # assert trials[count-1][-1][0] == 18\n",
    "                print('WARNING: parsed trial {} does not end in 18'.format(count))\n",
    "        else:\n",
    "            trials[count].append(c)\n",
    "\n",
    "    if verbose:\n",
    "        print('found {} trials with {} codes'.format(count, len(codes)))\n",
    "\n",
    "    return fs, codes, trials\n",
    "\n",
    "def ranges(i):\n",
    "    \"\"\" just provides better print() output for trials \"\"\"\n",
    "    for a, b in itertools.groupby(enumerate(i), lambda pair: pair[1] - pair[0]):\n",
    "        b = list(b)\n",
    "        yield b[0][1], b[-1][1]\n",
    "\n",
    "# this is the work-horse function that aligns the trials in the behavioral files with those in the neural ones\n",
    "def match_trials(bhv, codes, trials, fs, margin=0.1, verbose=False):\n",
    "    \"\"\" matches codes from behavioral data with neural events - returns dictionary of trials \"\"\"\n",
    "    matches = {}\n",
    "    c = 0\n",
    "    cmax = 0\n",
    "    for tr in bhv:\n",
    "        bhv_tr_len = np.asarray(bhv[tr]['BehavioralCodes']['CodeTimes'][-1] - bhv[tr]['BehavioralCodes']['CodeTimes'][0], dtype=int)\n",
    "        m = False\n",
    "        while c < len(trials) and m == False:\n",
    "            # check for valid trials\n",
    "            if len(trials[c]) > 1:\n",
    "                tr_codes = [j[0] for j in trials[c]]\n",
    "                if trials[c][0][0] == 9 and 18 in tr_codes:\n",
    "                    tr_start = trials[c][0][1]\n",
    "\n",
    "                    i18 = tr_codes.index(18)\n",
    "\n",
    "                    tr_end = trials[c][i18][1]\n",
    "                    nrl_tr_len = (tr_end - tr_start) / fs * 1000 # convert to milliseconds\n",
    "                    diff = 1 - nrl_tr_len/bhv_tr_len\n",
    "                    if abs(diff) < margin:\n",
    "                        if verbose:\n",
    "                            print('Aligned Trial {} (acc: {:.3f}%)'.format(tr, diff*100))\n",
    "                        matches[tr] = trials[c]\n",
    "                        m = True\n",
    "                        c += 1\n",
    "                        cmax = c\n",
    "                    else:\n",
    "                        c += 1\n",
    "                else:\n",
    "                    c += 1\n",
    "            else:\n",
    "                c+=1\n",
    "        c = cmax\n",
    "\n",
    "        if m == False and verbose:\n",
    "            print('could not find match for {}'.format(tr))\n",
    "\n",
    "    match_range = ranges(matches.keys())\n",
    "\n",
    "    rstr = []\n",
    "    for i in match_range:\n",
    "        if i[0] == i[1]:\n",
    "            rstr.append('{}'.format(i[0]))\n",
    "        else:\n",
    "            rstr.append('{}-{}'.format(i[0], i[1]))\n",
    "\n",
    "    match_range = ', '.join(list(rstr))\n",
    "    print('found matches for trials {}'.format(match_range))\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d1df7",
   "metadata": {
    "id": "3d2d1df7"
   },
   "source": [
    "## 1. Task and Data Description\n",
    "\n",
    "First, let's discuss the task. Participants underwent a memory task where they saw a series of 5-second movie clips. Each clip was accompanied by a circle that varied in color and location (the circles appeared in a location around the movie clip). This is the encoding phase. The participants then saw each clip again and then were to recall the properties of the circle (color, location) for the clip. This is the same day recall phase. The recall was then repeated the next day, which is the next day recall phase. This describes the full implementation of the task once.\n",
    "\n",
    "The data can be found in the following directory on Oscar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc895fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath('/oscar/data/brainstorm-ws/seeg_data/Memory Task Data/Epilepsy/Monitoring/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc81610",
   "metadata": {},
   "source": [
    "This directory contains a lot of folders corresponding to different participant data. The folders will look something like this: `2020-11-12_e0010GP_00` where `2020-11-12` corresponds to the data the data were recorded, `e0010GP` corresponds to the participant ID and `00` corresponds to the recording number of that participant (so, the first set of the participant's data is `00`, the second set of participant's is `01` and so forth). \n",
    "\n",
    "Let's see what folders exist in this directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd312b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[filename for filename in os.listdir(data_path) if '.csv' not in filename and '.ipynb' not in filename] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca1ed31",
   "metadata": {},
   "source": [
    "Remember that fully conducting the memory experiment takes 2 days, so to get a full dataset from one participant, we will need two of these folders. For example, `2020-11-12_e0010GP_00` corresponds to participant `e0010GP`'s first day of recording, which will contain the encoding phase and the same-day recall phase, while `2020-11-13_e0010GP_01` corresponds to participant `e0010GP`'s second day of recording, which contains the next-day recall phase.\n",
    "\n",
    "You might have noticed, however, that some participants have more than just two folders. This can occur when the participants conducted the task more than one time. For example `2020-11-13_e0010GP_02` corresponds to participant `e0010GP`'s third day of recording, which contains the encoding phase and the same-day recall phase of this participant conducting the task a second time. Although you may use this data if you like, this script will only be organizing data from each participant the first time they conducted the task. \n",
    "\n",
    "Unfortunately, for various reasons, the post-fixes (`00`, `01`, `02`, ...) are not always fully consistent in that `00` indicates the encoding and same-day recall phase of the first time the task was conducted, and `01` indicates the next-day recall phase of the first time the task was conducted. So, instead of relying on these post-fixes, we will here manually determine which folders indicate the first and second day that the corresponding participant conducted the task the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515702c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Participants e0014VG, e0016YR, and e0022ZG do not have next-day recall, so will be ignored in this script. \n",
    "#They do all have encoding and same day recall, so they may still be useful to you if you would like to include them.\n",
    "\n",
    "participants_of_interest = [\n",
    "    ['e0010GP_00', 'e0010GP_01'],\n",
    "    ['e0011XQ_00', 'e0011XQ_01'],\n",
    "    ['e0017MC_00', 'e0017MC_01'],\n",
    "    ['e0019VQ_00', 'e0019VQ_01'],\n",
    "    ['e0020JA_00', 'e0020JA_01'],\n",
    "    ['e0024DV_00', 'e0024DV_01'],\n",
    "    ['e0013LW_02', 'e0013LW_03'],\n",
    "    ['e0015TJ_01', 'e0015TJ_02']]\n",
    "\n",
    "participants_of_interest_flattened = [participant_filename for participant_filenames in participants_of_interest for participant_filename in participant_filenames]\n",
    "participant_fullnames_flattened = [filename for filename in os.listdir(data_path) if '_'.join(filename.split('_')[-2:]) in participants_of_interest_flattened] \n",
    "participant_fullnames = np.array(participant_fullnames_flattened).reshape(-1,2).tolist()\n",
    "\n",
    "[print(participant_fullname) for participant_fullname in participant_fullnames];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc5c06b",
   "metadata": {},
   "source": [
    "## 2. Re-Organizing the Data\n",
    "\n",
    "The following code is the meat of this script. It will extract data for each participant, dependent on the list provided above, re-organize it, and save it into a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates through all participants\n",
    "for participant_filenames in participant_fullnames: \n",
    "    \n",
    "    #Create participant specific dataframes\n",
    "    times = [f\"Time{str(datapoint).zfill(4)}\" for datapoint in range(5120)]\n",
    "    participant_data = pd.DataFrame(columns=['participant_id','Phase','Condition','Electrode']+times)\n",
    "    \n",
    "    #Iterates through Day 0 and Day 1. \n",
    "    #Day 0 includes the encoding phase and the same-day recall phase while Day 1 includes the next-day recall phase.\n",
    "    for day, participant_filename in enumerate(participant_filenames):\n",
    "        print(f\"\\nParticipant Filename: {participant_filename}\")\n",
    "\n",
    "        #Determine metadata and filenames\n",
    "        participant_id = participant_filename.split('_')[-2]\n",
    "        participants_filenames = os.listdir(f\"{data_path}/{participant_filename}\")\n",
    "        participant_electrodes = [p_file.split('-')[-1].replace('.pbz2','') for p_file in participants_filenames if '.pbz2' in p_file and 'Events.pbz2' not in p_file]\n",
    "        participant_neural_filenames = [p_file for p_file in participants_filenames if '.pbz2' in p_file and 'Events.pbz2' not in p_file]\n",
    "\n",
    "        #Iterate through phases.\n",
    "        #Day 0 contains Phases A and B, which are encoding and same-day recall, respectively\n",
    "        #Day 1 contains Phase A (which is different from Day 0's phase A), which is next-day recall.\n",
    "        phases = [['A','B'] if day == 0 else ['A']][0]\n",
    "        phases = ['C'] if day == 1 and participant_id == 'e0015TJ' else phases #One participant has a different naming convention\n",
    "        \n",
    "        #Iterate through the phases we just defined\n",
    "        for phase in phases:\n",
    "            \n",
    "            #Determine filenames\n",
    "            participant_beh = f\"{data_path}/{participant_filename}/{participant_filename[:-2]}{phase}.mat\"\n",
    "            participant_events = f\"{data_path}/{participant_filename}/{participant_filename[:-2]}Events.pbz2\"\n",
    "            \n",
    "            #Create a label to better signify the current phase\n",
    "            if day == 0 and phase == 'A':\n",
    "                phase_dict = 'Encoding'\n",
    "            elif day == 0 and phase == 'B':\n",
    "                phase_dict = 'SameDayRecall'\n",
    "            elif day == 1:\n",
    "                phase_dict = 'NextDayRecall'\n",
    "\n",
    "            #Print report\n",
    "            print(f\"\\nID: {participant_id}\")\n",
    "            print(f\"Day: {day}\")\n",
    "            print(f\"Phase: {phase_dict}\")\n",
    "\n",
    "            #Load and navigate the data using Bryan Zheng's functions\n",
    "            bhv = read_bhv(participant_beh)\n",
    "            fs, codes, trials = find_trials(participant_events)\n",
    "            matched_trials = match_trials(bhv, codes, trials, fs)\n",
    "\n",
    "            #Iterate through electrodes\n",
    "            for ei, electrode in enumerate(tqdm(participant_neural_filenames)):\n",
    "\n",
    "                #Load current electrodes data using Bryan Zheng's function\n",
    "                participant_neural = load_pkl(f\"{data_path}/{participant_filename}/{electrode}\")\n",
    "                \n",
    "                #Iterate through the trials\n",
    "                for trial in bhv.keys():\n",
    "                    \n",
    "                    #Determine the video clip being watched (video clip labels range from 1 to 30)\n",
    "                    trial_condition = bhv[trial]['Condition']\n",
    "                    \n",
    "                    #Determine current electrode being processed\n",
    "                    current_electrode = participant_electrodes[ei]\n",
    "\n",
    "                    #Determine the start and end time of the video clip\n",
    "                    start_time = matched_trials[trial][0][1]\n",
    "                    end_time = matched_trials[trial][-1][1]\n",
    "\n",
    "                    #Segment the data to only contain the video clip\n",
    "                    trial_neural = list(participant_neural['signal'][start_time:end_time][:int(5*participant_neural['fs'])])\n",
    "                    \n",
    "                    #Add metadata and data to the participant-specific dataframe to later be saved\n",
    "                    participant_data.loc[len(participant_data)] = [participant_id, phase_dict, trial_condition, current_electrode]+trial_neural                \n",
    "\n",
    "    #Save participant data to a csv file\n",
    "    participant_data.to_csv(f\"{data_path}/{participant_id}_combined.csv\", index=False)\n",
    "    \n",
    "    #Add participant data to a dictionary that will be saved to contain all participants\n",
    "    all_data[participant_id] = participant_data\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
